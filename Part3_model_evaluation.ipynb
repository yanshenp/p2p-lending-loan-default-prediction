{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models' performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_dir = r'C:\\Users\\pangy\\OneDrive - Asia Pacific University\\Capstone project'\n",
    "os.chdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pangy\\AppData\\Local\\Temp\\ipykernel_19160\\332499261.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Load all the datasets \n",
    "import pandas as pd\n",
    "train_x_fs = pd.read_csv('CP_datasets2/train_x_fs.csv')\n",
    "train_y = pd.read_csv('CP_datasets2/train_y.csv')\n",
    "test_y = pd.read_csv('CP_datasets2/test_y.csv')\n",
    "test_x_fs = pd.read_csv('CP_datasets2/test_x_fs.csv')\n",
    "train_x = pd.read_csv('CP_datasets2/train_x.csv')\n",
    "test_x = pd.read_csv('CP_datasets2/test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((430971, 35), (430971, 1), (107743, 1), (107743, 35))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_fs.shape,train_y.shape,test_y.shape,test_x_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained models will be loaded into the environment of the notebook for model evaluation and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pangy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\pangy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Import fine-tuned logistic regression model\n",
    "with open('CP_notebook/LogisticRegression_model/lr_finetuned_model.pkl','rb') as f:\n",
    "    lr_finetuned_model = pickle.load(f)\n",
    "\n",
    "# Import fine-tuned LightGBM model\n",
    "with open('CP_notebook/LightGBM_model/lgbm_finetuned_model.pkl','rb') as f:\n",
    "    lightgbm_finetuned_model = pickle.load(f)\n",
    "    \n",
    "# Import fine-tuned SVM model\n",
    "with open('CP_notebook/SVM_model/svm_finetuned_model.pkl','rb') as f:\n",
    "    svm_finetuned_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to evaluate the performance of models was defined and created in the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following codes will create a function to test the performance of models using the testing dataset\n",
    "def model_performance(model_name, model_type, test_x, test_y):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "    # Predict the y value using the model\n",
    "    y_pred = model_name.predict(test_x)\n",
    "    # Calculate evaluation metrics using metrics in sklearn\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    precision = precision_score(test_y, y_pred)\n",
    "    recall = recall_score(test_y, y_pred)\n",
    "    f1 = f1_score(test_y, y_pred)\n",
    "\n",
    "    # Make sure that the metrics to output result in four significant figures \n",
    "    accuracy = format(accuracy, '.4f')\n",
    "    precision = format(precision, '.4f')\n",
    "    recall = format(recall, '.4f')\n",
    "    f1 = format(f1, '.4f')\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f'-----{model_type}-----')\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    # And also return the evaluation metrics as a dictionary\n",
    "    return {\n",
    "        'Model Type': model_type,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models using the metric in scikit learn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Logistic Regression model-----\n",
      "Accuracy: 0.6439\n",
      "Precision: 0.6426\n",
      "Recall: 0.6485\n",
      "F1 Score: 0.6455\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "-----LightGBM model-----\n",
      "Accuracy: 0.6526\n",
      "Precision: 0.6488\n",
      "Recall: 0.6655\n",
      "F1 Score: 0.6570\n",
      "\n",
      "\n",
      "-----Support vector Machine model-----\n",
      "Accuracy: 0.6442\n",
      "Precision: 0.6431\n",
      "Recall: 0.6479\n",
      "F1 Score: 0.6455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model Type': 'Support vector Machine model',\n",
       " 'Accuracy': '0.6442',\n",
       " 'Precision': '0.6431',\n",
       " 'Recall': '0.6479',\n",
       " 'F1 Score': '0.6455'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance(lr_finetuned_model,'Logistic Regression model', test_x_fs, test_y)\n",
    "print('\\n')\n",
    "model_performance(lightgbm_finetuned_model,'LightGBM model', test_x_fs, test_y)\n",
    "print('\\n')\n",
    "model_performance(svm_finetuned_model,'Support vector Machine model', test_x_fs, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Logistic Regression-----\n",
      "Accuracy: 0.6439\n",
      "Precision: 0.6426\n",
      "Recall: 0.6485\n",
      "F1 Score: 0.6455\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "-----LightGBM-----\n",
      "Accuracy: 0.6526\n",
      "Precision: 0.6488\n",
      "Recall: 0.6655\n",
      "F1 Score: 0.6570\n",
      "-----Support Vector Machine-----\n",
      "Accuracy: 0.6442\n",
      "Precision: 0.6431\n",
      "Recall: 0.6479\n",
      "F1 Score: 0.6455\n"
     ]
    }
   ],
   "source": [
    "# Create a dictiobary and store model performances into dictionary\n",
    "model_evaluation_dict = []\n",
    "\n",
    "# Now add the result of each model to the dict\n",
    "# Calculate and store performance for each model\n",
    "model_evaluation_dict.append(model_performance(lr_finetuned_model, 'Logistic Regression', test_x_fs, test_y))\n",
    "model_evaluation_dict.append(model_performance(lightgbm_finetuned_model, 'LightGBM', test_x_fs, test_y))\n",
    "model_evaluation_dict.append(model_performance(svm_finetuned_model, 'Support Vector Machine', test_x_fs, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_result = pd.DataFrame(model_evaluation_dict)\n",
    "model_evaluation_result.to_csv('CP_datasets2/models_performance.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
